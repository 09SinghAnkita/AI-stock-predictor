{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5e588-0877-43a8-8e28-52f61e977c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your Alpha Vantage API key\n",
    "API_KEY = 'OQJ4ER1FJIKJQ2MX'\n",
    "\n",
    "# Function to fetch stock data from Alpha Vantage\n",
    "def fetch_stock_data(symbol, output_size='compact'):\n",
    "    # API URL for Alpha Vantage's TIME_SERIES_DAILY endpoint\n",
    "    url = f\"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"TIME_SERIES_DAILY\",\n",
    "        \"symbol\": symbol,\n",
    "        \"outputsize\": output_size,  # 'compact' for last 100 data points, 'full' for full data\n",
    "        \"apikey\": API_KEY,\n",
    "        \"datatype\": \"csv\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the response content as a CSV file\n",
    "        with open(f'{symbol}_stock_data.csv', 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Data saved to {symbol}_stock_data.csv\")\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "\n",
    "# Fetch data for a specific stock (e.g., AAPL for Apple)\n",
    "fetch_stock_data('AAPL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af55eb-ef50-4d81-8118-67f3a18294b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the stock data from the CSV file\n",
    "data = pd.read_csv('AAPL_stock_data.csv')  # Ensure the filename matches your CSV\n",
    "\n",
    "# Convert 'timestamp' column to datetime and set it as the index\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Drop any rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "data.to_csv('cleaned_AAPL_stock_data.csv')\n",
    "\n",
    "print(\"Cleaned data saved to cleaned_AAPL_stock_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfe5d3-205f-41d9-a275-069bdbae6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the path to your Django project\n",
    "sys.path.append('C:/Users/Win/Desktop/Project/Stock Project')\n",
    "\n",
    "# Set the Django settings module\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'stock_project.settings')\n",
    "\n",
    "# Set up Django\n",
    "import django\n",
    "django.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f856e4-b7e6-4181-b6e5-a797a65252ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the path to your Django project\n",
    "sys.path.append('C:/Users/Win/Desktop/Project/Stock Project')\n",
    "\n",
    "# Set the Django settings module\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'stock_project.settings')\n",
    "\n",
    "# Set up Django\n",
    "import django\n",
    "django.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06483151-8139-48aa-86a1-b29485bf57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the path to your Django project\n",
    "sys.path.append('C:/Users/Win/Desktop/Project/Stock Project')\n",
    "\n",
    "# Set the Django settings module\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'stock_project.settings')\n",
    "\n",
    "# Set up Django\n",
    "import django\n",
    "django.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d02eae3-5793-4988-86a9-4766269936c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the path to the folder containing 'manage.py'\n",
    "sys.path.append('C:/Users/Win/Desktop/Project/Stock Project')\n",
    "\n",
    "# Set the Django settings module to 'stocks_simplified.settings'\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'stocks_simplified.settings')\n",
    "\n",
    "# Set up Django\n",
    "import django\n",
    "django.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb58b46-4f8a-4b80-9167-4feb8d2510f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the path to the folder containing 'manage.py'\n",
    "sys.path.append('C:/Users/Win/Desktop/Project/Stock Project')\n",
    "\n",
    "# Set the Django settings module to 'stocks_simplified.settings'\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'stocks_simplified.settings')\n",
    "\n",
    "# Set up Django\n",
    "import django\n",
    "django.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab7ecc-249b-4672-b775-1c04772e9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockdata.models import HistoricalData\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch all data from HistoricalData model\n",
    "data = HistoricalData.objects.all().values('stock__symbol', 'date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume')\n",
    "\n",
    "# Convert the queryset to a pandas DataFrame\n",
    "df = pd.DataFrame(list(data))\n",
    "\n",
    "# Display the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c538970-ba9e-428d-a5bd-cefab2849ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockdata.models import HistoricalData\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch all data from HistoricalData model\n",
    "data = HistoricalData.objects.all().values('stock__symbol', 'date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume')\n",
    "\n",
    "# Convert the queryset to a pandas DataFrame\n",
    "df = pd.DataFrame(list(data))\n",
    "\n",
    "# Display the data\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6f6033-34cb-4051-8ce0-a66135208307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockdata.models import HistoricalData\n",
    "import pandas as pd\n",
    "from asgiref.sync import sync_to_async\n",
    "\n",
    "async def fetch_data():\n",
    "    # Fetch data asynchronously\n",
    "    data = await sync_to_async(list)(HistoricalData.objects.values(\n",
    "        'stock__symbol', 'date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume'\n",
    "    ))\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Return or print the first few rows of the DataFrame\n",
    "    return df.head()\n",
    "\n",
    "# Call the asynchronous function\n",
    "df_head = await fetch_data()\n",
    "print(df_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d76428-53bf-43cd-9b53-e2cbb209fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockdata.models import HistoricalData\n",
    "import pandas as pd\n",
    "from asgiref.sync import sync_to_async\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Fetch data from the database asynchronously\n",
    "async def fetch_data():\n",
    "    # Fetch the stock data\n",
    "    data = await sync_to_async(list)(HistoricalData.objects.values(\n",
    "        'stock__symbol', 'date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume'\n",
    "    ))\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Step 2: Prepare data for each stock symbol\n",
    "def prepare_lstm_data(df, time_step=60):\n",
    "    stock_symbols = df['stock__symbol'].unique()\n",
    "    predictions = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        stock_data = df[df['stock__symbol'] == symbol]\n",
    "        close_prices = stock_data['close_price'].values.reshape(-1, 1)\n",
    "\n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(close_prices)\n",
    "\n",
    "        # Prepare training data\n",
    "        x_train, y_train = [], []\n",
    "        for i in range(len(scaled_data) - time_step):\n",
    "            x_train.append(scaled_data[i:i+time_step, 0])\n",
    "            y_train.append(scaled_data[i + time_step, 0])\n",
    "        \n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "        # Step 3: Build and train LSTM model for each stock\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "        # Step 4: Predict the next day's price for each stock\n",
    "        last_60_days = scaled_data[-time_step:]\n",
    "        last_60_days = last_60_days.reshape(1, -1, 1)\n",
    "        predicted_price = model.predict(last_60_days)\n",
    "        predicted_price_actual = scaler.inverse_transform(predicted_price)\n",
    "\n",
    "        # Store predictions\n",
    "        predictions[symbol] = predicted_price_actual[0][0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Step 5: Run the prediction process\n",
    "df = await fetch_data()  # Fetch the data\n",
    "predictions = prepare_lstm_data(df)  # Prepare and predict\n",
    "\n",
    "# Print predictions for all stocks\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9ac7b-c2f2-4b81-954c-2aba82ed5bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb5cc7-3024-4821-a9d3-1eed2fd0413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('stock_prediction_model.pkl','wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b6567-8c84-4aee-a708-a9b71b480e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockdata.models import HistoricalData\n",
    "import pandas as pd\n",
    "from asgiref.sync import sync_to_async\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Fetch data from the database asynchronously\n",
    "async def fetch_data():\n",
    "    # Fetch the stock data\n",
    "    data = await sync_to_async(list)(HistoricalData.objects.values(\n",
    "        'stock__symbol', 'date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume'\n",
    "    ))\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Step 2: Prepare data for each stock symbol\n",
    "def prepare_lstm_data(df, time_step=60):\n",
    "    stock_symbols = df['stock__symbol'].unique()\n",
    "    predictions = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        stock_data = df[df['stock__symbol'] == symbol]\n",
    "        close_prices = stock_data['close_price'].values.reshape(-1, 1)\n",
    "\n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(close_prices)\n",
    "\n",
    "        # Prepare training data\n",
    "        x_train, y_train = [], []\n",
    "        for i in range(len(scaled_data) - time_step):\n",
    "            x_train.append(scaled_data[i:i+time_step, 0])\n",
    "            y_train.append(scaled_data[i + time_step, 0])\n",
    "        \n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "        # Step 3: Build and train LSTM model for each stock\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "        # Step 4: Predict the next day's price for each stock\n",
    "        last_60_days = scaled_data[-time_step:]\n",
    "        last_60_days = last_60_days.reshape(1, -1, 1)\n",
    "        predicted_price = model.predict(last_60_days)\n",
    "        predicted_price_actual = scaler.inverse_transform(predicted_price)\n",
    "\n",
    "        # Store predictions\n",
    "        predictions[symbol] = predicted_price_actual[0][0]\n",
    "\n",
    "        # Step 5: Save the trained model to a file for later use\n",
    "        model_filename = f'model_{symbol}.pkl'  # Save each model with the stock symbol name\n",
    "        with open(model_filename, 'wb') as model_file:\n",
    "            pickle.dump(model, model_file)  # Save the model to a .pkl file\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Step 5: Run the prediction process\n",
    "df = await fetch_data()  # Fetch the data\n",
    "predictions = prepare_lstm_data(df)  # Prepare and predict\n",
    "\n",
    "# Print predictions for all stocks\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321650d-6e3a-48cf-82be-48ed8d51d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockdata.models import HistoricalData\n",
    "import pandas as pd\n",
    "from asgiref.sync import sync_to_async\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Fetch data from the database asynchronously\n",
    "async def fetch_data():\n",
    "    # Fetch the stock data\n",
    "    data = await sync_to_async(list)(HistoricalData.objects.values(\n",
    "        'stock__symbol', 'date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume'\n",
    "    ))\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Step 2: Prepare data for each stock symbol\n",
    "def prepare_lstm_data(df, time_step=60):\n",
    "    stock_symbols = df['stock__symbol'].unique()\n",
    "    predictions = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        stock_data = df[df['stock__symbol'] == symbol]\n",
    "        close_prices = stock_data['close_price'].values.reshape(-1, 1)\n",
    "\n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(close_prices)\n",
    "\n",
    "        # Prepare training data\n",
    "        x_train, y_train = [], []\n",
    "        for i in range(len(scaled_data) - time_step):\n",
    "            x_train.append(scaled_data[i:i+time_step, 0])\n",
    "            y_train.append(scaled_data[i + time_step, 0])\n",
    "        \n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "        # Step 3: Build and train LSTM model for each stock\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "        # Step 4: Predict the next day's price for each stock\n",
    "        last_60_days = scaled_data[-time_step:]\n",
    "        last_60_days = last_60_days.reshape(1, -1, 1)\n",
    "        predicted_price = model.predict(last_60_days)\n",
    "        predicted_price_actual = scaler.inverse_transform(predicted_price)\n",
    "\n",
    "        # Store predictions\n",
    "        predictions[symbol] = predicted_price_actual[0][0]\n",
    "\n",
    "        # Step 5: Save the trained model to a file for later use\n",
    "        model_filename = f'model_{symbol}.pkl'  # Save each model with the stock symbol name\n",
    "        with open(model_filename, 'wb') as model_file:\n",
    "            pickle.dump(model, model_file)  # Save the model to a .pkl file\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Step 5: Run the prediction process\n",
    "df = await fetch_data()  # Fetch the data\n",
    "predictions = prepare_lstm_data(df)  # Prepare and predict\n",
    "\n",
    "# Print predictions for all stocks\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657caeb5-6fd3-4652-a40a-ae3def950167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
